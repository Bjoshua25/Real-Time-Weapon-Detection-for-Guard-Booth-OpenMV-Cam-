{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "111047ef",
   "metadata": {},
   "source": [
    "# Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "841f8004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82bd5edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Class counts before augmentation: {'THREAT': 698, 'NO_THREAT': 493}\n",
      "[i] Processing class 'THREAT' with augment_factor=2\n",
      "[i] Processing class 'NO_THREAT' with augment_factor=2\n",
      "[✓] After augmentation, class distribution: {'NO_THREAT': 1479, 'THREAT': 2094}\n",
      "[✓] Balanced MobileNet-ready dataset saved.\n",
      "[✓] Train: (2501, 224, 224, 3), Val: (536, 224, 224, 3), Test: (536, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# === CONFIG ===\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "processed_dir = \"c:/Users/user/Documents/Real_time_weapon_detection/processed_data\"\n",
    "img_size = (224, 224)  # MobileNet expected size\n",
    "base_augment_factor = 2\n",
    "\n",
    "# Threat mapping\n",
    "threat_map = {\n",
    "    \"human_with_weapon\": \"THREAT\",\n",
    "    \"weapon_only\": \"THREAT\",\n",
    "    \"human_only\": \"NO_THREAT\",\n",
    "    \"no_threat\": \"NO_THREAT\"\n",
    "}\n",
    "\n",
    "# === AUGMENTATION FUNCTION (RGB) ===\n",
    "def augment_image(img):\n",
    "    \"\"\"Apply random augmentations to an RGB image.\"\"\"\n",
    "    if random.random() > 0.5:\n",
    "        img = ImageOps.mirror(img)  # Flip\n",
    "\n",
    "    angle = random.uniform(-15, 15)\n",
    "    img = img.rotate(angle)\n",
    "\n",
    "    # Brightness & contrast adjustments\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    img = enhancer.enhance(random.uniform(0.8, 1.2))\n",
    "\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    img = enhancer.enhance(random.uniform(0.8, 1.2))\n",
    "\n",
    "    return img\n",
    "\n",
    "# === STEP 1: COUNT FILES PER CLASS ===\n",
    "class_counts = {\"THREAT\": 0, \"NO_THREAT\": 0}\n",
    "class_files = {\"THREAT\": [], \"NO_THREAT\": []}\n",
    "\n",
    "for label in os.listdir(processed_dir):\n",
    "    class_dir = os.path.join(processed_dir, label)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "    mapped_label = threat_map[label]\n",
    "    files = [f for f in os.listdir(class_dir) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    class_counts[mapped_label] += len(files)\n",
    "    class_files[mapped_label].extend([(os.path.join(class_dir, f), mapped_label) for f in files])\n",
    "\n",
    "print(f\"[i] Class counts before augmentation: {class_counts}\")\n",
    "\n",
    "# === STEP 2: BALANCE DATASET WITH AUGMENTATION ===\n",
    "max_count = max(class_counts.values())\n",
    "images, labels = [], []\n",
    "\n",
    "for mapped_label, files in class_files.items():\n",
    "    num_original = len(files)\n",
    "    if num_original < max_count:\n",
    "        extra_needed = max_count - num_original\n",
    "        augment_factor = max(base_augment_factor, int(np.ceil(extra_needed / num_original)))\n",
    "    else:\n",
    "        augment_factor = base_augment_factor\n",
    "\n",
    "    print(f\"[i] Processing class '{mapped_label}' with augment_factor={augment_factor}\")\n",
    "\n",
    "    for img_path, lbl in files:\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\").resize(img_size)\n",
    "\n",
    "            # Add original (keep 0–255 values for MobileNet preprocessing later)\n",
    "            images.append(np.array(img, dtype=np.float32))\n",
    "            labels.append(lbl)\n",
    "\n",
    "            # Augment\n",
    "            for _ in range(augment_factor):\n",
    "                aug_img = augment_image(img)\n",
    "                images.append(np.array(aug_img, dtype=np.float32))\n",
    "                labels.append(lbl)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[✗] Could not process {img_path}: {e}\")\n",
    "\n",
    "# === STEP 3: ENCODE LABELS ===\n",
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(labels)  # THREAT=1, NO_THREAT=0 (depending on fit order)\n",
    "\n",
    "# === STEP 4: TO NUMPY ARRAYS ===\n",
    "X = np.array(images)  # Shape: (N, 224, 224, 3)\n",
    "y = np.array(labels_encoded)\n",
    "\n",
    "print(f\"[✓] After augmentation, class distribution: {dict(zip(le.classes_, np.bincount(y)))}\")\n",
    "\n",
    "# === STEP 5: SPLIT ===\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# === STEP 6: SAVE TO DISK ===\n",
    "np.savez(\n",
    "    \"dataset_rgb_224_binary_balanced.npz\",\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_val=X_val, y_val=y_val,\n",
    "    X_test=X_test, y_test=y_test,\n",
    "    label_names=le.classes_\n",
    ")\n",
    "\n",
    "print(f\"[✓] Balanced MobileNet-ready dataset saved.\")\n",
    "print(f\"[✓] Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed7c160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
