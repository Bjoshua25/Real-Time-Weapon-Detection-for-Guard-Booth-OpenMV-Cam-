# üõ°Ô∏è **Real-Time Weapon Detection for Guard Booth (OpenMV Cam)**

---

## üöÄ **1. Project Overview**

**Objective:**
To develop a lightweight, real-time embedded system using the **OpenMV Cam** that detects weapons in a guard booth by classifying visual input as:

* Human only
* Human with weapon
* Weapon only
* No threat

**Target Deployment:**
Military checkpoints, border posts, guard booths, or secure facilities

**Expected Behavior:**

* Continuously monitor video stream
* Classify scene from frame snapshot
* Trigger alerts for weapon-related classes
* Operate fully offline, on low power, without internet

---

## üìÖ **2. Project Phases & Timeline**

| Phase                                 | Tasks                                                   | Timeline  |
| ------------------------------------- | ------------------------------------------------------- | --------- |
| **Phase 1: Planning & Setup**         | Define scope, install tools, OpenMV IDE, hardware setup | Day 1‚Äì2   |
| **Phase 2: Dataset Collection**       | Collect & label images for 4 classes                    | Day 3‚Äì7   |
| **Phase 3: Model Training**           | Train lightweight CNN with TensorFlow                   | Day 8‚Äì10  |
| **Phase 4: Convert & Deploy**         | Convert model to TFLite, upload to OpenMV               | Day 11‚Äì12 |
| **Phase 5: Testing & Validation**     | Live testing, tune thresholds, evaluate accuracy        | Day 13‚Äì14 |
| **Phase 6: Response Mechanisms**      | Add buzzer, LED, SD save, GSM alert (optional)          | Day 15‚Äì17 |
| **Phase 7: Final Integration & Demo** | Enclose in booth, power test, demo                      | Day 18‚Äì20 |

---

## üóÇÔ∏è **3. Dataset Plan**

You need a labeled dataset with **4 categories**:

| Class                   | Description                                 | Sample Count             |
| ----------------------- | ------------------------------------------- | ------------------------ |
| `0` ‚Äì No Threat         | Empty booth, walls, random objects          | 300+                     |
| `1` ‚Äì Human Only        | Soldiers, civilians, people without weapons | 300+                     |
| `2` ‚Äì Weapon Only       | Guns/knives alone (table, floor)            | 300+                     |
| `3` ‚Äì Human With Weapon | People holding weapons                      | 300‚Äì500 (priority class) |

### Notes:

* Resize all images to `96x96` px
* Convert to grayscale (or RGB if needed)
* Augment images (flip, blur, brightness) to boost training

---

## üß† **4. Model Design**

You‚Äôll build a **TinyCNN** suitable for OpenMV:

* Input: 96x96 grayscale
* Layers: Conv ‚Üí Pool ‚Üí Conv ‚Üí Pool ‚Üí Dense ‚Üí Softmax
* Output: 4 classes

Training tools:

* Python, TensorFlow/Keras
* Train on your laptop or Colab
* Convert to `.tflite` using TFLite Converter

---

## ‚öôÔ∏è **5. Model Deployment (OpenMV)**

* Copy `.tflite` model to SD card or board flash
* Use MicroPython + OpenMV's `tf` module
* Script to:

  * Capture live frame
  * Run `.classify()` on image
  * Parse output to label
  * Trigger response (buzzer, print, LED, etc.)

---

## üß™ **6. Response System**

Depending on detection result, trigger:

| Action                           | Hardware Needed                 |
| -------------------------------- | ------------------------------- |
| **Buzzer** or **LED alert**      | GPIO + piezo buzzer or LED      |
| **Save frame to SD**             | Use `img.save("/sd/frame.jpg")` |
| **GSM/SIM alert**                | Integrate ESP32/Sim800L module  |
| **Serial out to central system** | UART connection to main board   |

---

## üìä **7. Performance Evaluation**

Metrics to monitor:

* Classification Accuracy (on test set)
* False Positives / Negatives
* Inference time (should be < 200ms)
* Power usage (battery operation?)

---

## üì¶ **8. Hardware Setup**

| Component                      | Purpose               |
| ------------------------------ | --------------------- |
| **OpenMV Cam H7/H7 Plus**      | Vision + ML           |
| MicroSD card                   | Store model + images  |
| Piezo Buzzer / LEDs            | Alerts                |
| Power supply (5V)              | Standalone deployment |
| (Optional) WiFi / GSM Shield   | Remote alerts         |
| 3D-printed or wooden enclosure | Weather protection    |

---

## üìÅ **9. Folder/Project Structure (Local + OpenMV)**

```bash
weapon-detection-guard-booth/
‚îú‚îÄ‚îÄ dataset/
‚îÇ   ‚îú‚îÄ‚îÄ no_threat/
‚îÇ   ‚îú‚îÄ‚îÄ human_only/
‚îÇ   ‚îú‚îÄ‚îÄ weapon_only/
‚îÇ   ‚îî‚îÄ‚îÄ human_with_weapon/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ trained_model.h5
‚îÇ   ‚îî‚îÄ‚îÄ model.tflite
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ openmv_classify.py
‚îú‚îÄ‚îÄ deployment/
‚îÇ   ‚îú‚îÄ‚îÄ openmv_script.py
‚îÇ   ‚îî‚îÄ‚îÄ alerts/
‚îî‚îÄ‚îÄ README.md
```

---

## üß∞ **10. Tools Needed**

| Tool                             | Use                         |
| -------------------------------- | --------------------------- |
| **OpenMV IDE**                   | Deployment, camera control  |
| **TensorFlow / Keras**           | Model training              |
| **Python 3.8+**                  | Environment                 |
| **Colab or local Jupyter**       | Training environment        |
| **Image tools (CVAT, LabelImg)** | Dataset labeling (optional) |


